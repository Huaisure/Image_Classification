## <center> 项目二 图像分类
### <center> 刘淮硕 自动化系 2021013433

## 任务一 根据图像数据集，设计深度学习方法，解决图像分类问题

在 `data_preparation.py` 中进行数据的预处理，包括对图片的翻转和旋转，在任务二中，我将这一预处理部分删除，比较模型前后相同条件下的性能。

在 `model.py` 中定义模型架构，采用 ResNet 架构，手动搭建了 ResNet50 模型。`train.py` 脚本中为训练模型和保存模型，采用Adam优化器，后面也尝试了其他的优化器以比较不同优化器的影响。

在 `evaluate.py` 中根据模型的路径，对测试集进行预测，将正确率作为评判模型性能的标准

在训练24个epoch后，选取其中验证集正确率最高的模型，其在测试集上的正确率为 90.14%。

## 任务二 改变一些模型的结构，或训练方法，总结对模型性能的影响

### 2.1 数据预处理

在任务一中定义训练的模型中，我输入的数据经过了随机翻转和旋转，以增加输入图片的多样性。

```python
train_transform = transforms.Compose([
    transforms.Resize((150,150)),
    transforms.RandomHorizontalFlip(),#随机水平翻转
    transforms.RandomRotation(15),#随机旋转
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])#标准化，加快收敛速度
])
```
在删去这一预处理后，其他条件不变，再进行训练，可以发现模型再测试集上的准确率有所下降，为88.11%

### 2.2 不同优化器的选择

Adam 优化器是万金油，这也是我最开始选择使用Adam优化器的原因，可以较稳定快速的达到收敛；后来我尝试了 SGD 优化器，在少量 epoch 训练时，可以很快的收敛，但是会出现训练过程中loss突然增加，验证集准确率骤降的现象，也就是说训练的稳定性不高。

最终，采用SGD优化器的测试集准确率也不是很理想，为85.56%

### 2.3 模型结构的改变

#### 2.3.1 引入dropout

ResNet50 模型自身是并没有设置 dropout 层的，我尝试增加了dropout层，但是效果并不理想，准确率有所下降，为87.00%


#### 2.3.2 删除 BatchNorm

原模型中在每个卷积层后都加入了BatchNorm层，我将其删除，在训练后准确率下降为89.00%。但是我发现，这样训练的收敛速度并不像我想象的那样会有所下降，相反，在删除掉Batch Norm后，收敛的速度更快了，可能是数据集的质量较高吧。

## 任务三 可解释性问题

### 3.1 Grad-CAM 可视化

代码于 `grad_cam.py`

#### 3.1.1 简介

Grad-CAM（Gradient-weighted Class Activation Mapping）是一种用于解释和可视化卷积神经网络（CNN）决策过程的方法。它通过生成热力图来突出输入图像中的重要区域，这些区域对模型的决策有显著影响。Grad-CAM 不需要修改原有的 CNN 架构，因此适用于各种预训练模型。其核心思想是利用反向传播计算梯度，通过权重特征图生成可视化的类激活映射。

#### 3.1.2 实现过程

- 为了捕获卷积层的输出和梯度，在模型中注册钩子函数。这里，我们选择 ResNet-50 的最后一个卷积层（layer4[2].conv3）作为目标层。

```python
features = []
gradients = []

def save_gradient(grad):
    gradients.append(grad)

def get_features_hook(module, input, output):
    features.append(output)
    output.register_hook(save_gradient)

target_layer = model.layer4[2].conv3
target_layer.register_forward_hook(get_features_hook)
```

- 加载并预处理输入图像后，我们通过模型进行前向传播，得到预测输出。然后，通过反向传播计算目标类别的梯度。

- 使用捕获的梯度和特征图，我们计算每个特征图的权重。然后，对特征图进行加权求和，生成类激活映射（CAM）。最后，将生成的 CAM 热力图调整为输入图像的尺寸，并与原始图像叠加。


#### 3.1.3 效果

以 `data/imgs/43.jpg` 为例，热力图如下

![alt text](image.png)

我们可以注意到，网络所关注的部分为左上部分的雪山，也就通过这部分对图像进行的分类，这显然是合理的。

当然这也一定程度上反应，当前网络的训练是不充分的，因为它没有注意到右下角的雪山以及下面的湖面。


### 3.2 删去某几类观察模型性能

#### 3.2.1 实现

在 `train_less.py` 中实现，在原有的 `train.py` 基础上改进，通过对原来的 train_loader 进行筛选，删除其中的某几类，同时将`evaluate.py` 中的指标，增加每一类分类的准确率。

#### 3.2.2 删去 0，1类

删去 0、1 类后的结果

![alt text](image-1.png)

这个结果可以预见，因为毕竟分类的标准是数字，所以我删去的为最小的两类，整体的数字肯定是向上移动，所以数字越大，分类的效果会越好。下面我将删去中间的某一类比如第2类，再看看结果如何。

#### 3.2.3 删去2类

![alt text](image-2.png)

根据这两次实验，基本可以得到一个规律，从一侧去删去类别，那么整体的预测效果会在另一侧更好；如果从中间删去某一类别，那么两侧向中间效果越来越好，并且，相较于base，这种训练后的模型会在某些类别效果远超base，这也启发着我们，如果想要更专业化的模型，或许可以采取删去某些类别的方法。